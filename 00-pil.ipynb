{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rjmouron01/CSCE-3513-2022-Project/blob/main/00-pil.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "copyright"
      },
      "source": [
        "#### Copyright 2020 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24p97VuTvYVT"
      },
      "outputs": [],
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVmV0M74xwm7"
      },
      "source": [
        "# Manipulating an Image in Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuFjSsW53I9_"
      },
      "source": [
        "So far in this course, the data that we have encountered has been in some text format, such as comma separated values of strings and numbers. Other data has been directly loaded from scikit-learn as a `Bunch` of NumPy arrays, also containing strings and numbers.\n",
        "\n",
        "Data scientists sometimes find themselves working with collections of images, which are represented in a much more compact binary format. One of the most common examples of working with images is image classification, e.g., reverse image search.\n",
        "\n",
        "These images are often contained in a zip file, but they can also be in a directory on your computer or even on the internet. Once you have the images, you'll typically need to perform some type of preprocessing on them before you can do any sort of modeling.\n",
        "\n",
        "Most models expect a specific size of image, so you'll need to resize the images you feed your model if they differ from what is expected. Resizing might include cropping, stretching, padding, and scaling an image. Resizing to a smaller size also helps speed up your model by reducing the size of the input data.\n",
        "\n",
        "Images can also be encoded in many different ways. Some are grayscale; others are color. Color images might be encoded red-green-blue (RGB), blue-green-red (BGR), rgb-alpha, bgr-alpha, hue-saturation-lightness (HSL), hue-saturation-value (HSV), or some other encoding scheme. You will need to make sure your input images' encoding for all of your training data is the same.\n",
        "\n",
        "It is also common to normalize or standardize your images, which are just two different ways of reducing a wide range of pixel values (typically `0 `to `255` inclusive) into a tighter range.\n",
        "\n",
        "This might all sound like a lot of work, and it is. Fortunately, though, you don't have to worry too much about the details. There are numerous Python toolkits for manipulating images. In this unit, we will use the [Image](https://pillow.readthedocs.io/en/stable/reference/Image.html) and [ImageOps](https://pillow.readthedocs.io/en/stable/reference/ImageOps.html) modules from the [PIL (now called Pillow)](https://python-pillow.org/) library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk3COdKGIB7l"
      },
      "source": [
        "## Get Image\n",
        "\n",
        "The image that we will work with comes from [Pixabay](https://pixabay.com/photos/running-shoe-shoe-brooks-371624/). On the image page, you'll see the option to download it. Choose the 1920x1280 version of the image.\n",
        "\n",
        "After you have download the image to your computer, upload it into this Colab by running the code block below, clicking \"Choose Files\" in the form that appears, selecting the image that was just downloaded from the dialog box, and then pressing \"Open\". You should see messages about the file being uploaded and then eventually you'll see a notification that the file upload is complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euRZuE9MLHd0"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LboFaJ47r6x-"
      },
      "source": [
        "We can now take a look at our image to see if we uploaded it properly. To do this we will use [Matplotlib](https://matplotlib.org/) to display the image. But first we must load the image from the virtual machine hosting this Colab. Right now that image is stored on the virtual machine's hard drive.\n",
        "\n",
        "We'll use Pillow's `Image` module to open the file.\n",
        "\n",
        "Notice we use a [context block](https://docs.python.org/2.5/whatsnew/pep-343.html) to automatically close the image we opened in order to free up resources. We could also have just explicitly called close after we were done with the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhd_d5vzrc_h"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_file = \"running-shoe-g589ffd24f_1920.jpg\"\n",
        "\n",
        "with Image.open(image_file) as sneaker:\n",
        "  plt.imshow(sneaker)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Goq0Frawyuk"
      },
      "source": [
        "## Reshaping\n",
        "\n",
        "The image we currently have is wider than it is tall (landscape). It could have just as easily been taller than it is wide (portrait). It could have even been a square.\n",
        "\n",
        "Does the model care? In some ways it does, and in others it doesn't. The model needs consistent inputs. These could be of any shape and size, but they must be consistent throughout the modeling.\n",
        "\n",
        "First, we should know the size of the image we are working with. We can get that from Pillow by simply asking for the image size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfcdK_js_dQd"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_width_height = None\n",
        "\n",
        "with Image.open(image_file) as sneaker:\n",
        "  image_width_height = sneaker.size\n",
        "\n",
        "print(image_width_height)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u617UoBvzI_A"
      },
      "source": [
        "As expected, we have dimensions that indicate that we have an image in landscape: 1920 pixels wide and 1280 pixels tall.\n",
        "\n",
        "Now we have to figure out *if* and *how* to reshape it.\n",
        "\n",
        "For the question of *if*, let's assume that we expect a variable set of input shapes, and based on this, we believe that reshaping is necessary.\n",
        "\n",
        "Now we need to think about *how* to reshape the image. *How* can take many different formats:\n",
        "\n",
        "* Do we find the smaller dimension and just add blank padding to it until it is the same size as the larger dimension?\n",
        " * If so, do we pad one side? Both?\n",
        " * And what pixel value(s) do we use for the padding? Min? Max? Average? Other?\n",
        "* Do we crop a fixed portion of the image?\n",
        " * If so, do we center? Randomly crop? Multiple times?\n",
        "* Do we simply resize the image and let it be proportionally distorted?\n",
        "\n",
        "The answer to all of these questions completely depends on your problem domain and use case. This is actually part of the **science** of data science. Hypothesize, experiment, repeat.\n",
        "\n",
        "But for this Colab, we have to make a definitive decision. For simplicity, we will choose to evenly pad the smaller dimension with white pixels as evenly as possible on either side.\n",
        "\n",
        "To do this we first need to find the larger side (height or width) of the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nX-sWA3Z2uu3"
      },
      "outputs": [],
      "source": [
        "max_dimension = max(image_width_height)\n",
        "\n",
        "print(max_dimension)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8Uv3iI725Mb"
      },
      "source": [
        "Now we need to find out how much padding we need to add to each side of the image. The longer side shouldn't get any extra padding, and since we want to make the image a square, the shorter side should get enough padding to make it equal to the longer side.\n",
        "\n",
        "In this case we have a landscape picture. Therefore, no extra width is needed, and 640 pixels of height is needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-6VBoda3agD"
      },
      "outputs": [],
      "source": [
        "width_padding = max_dimension - image_width_height[0]\n",
        "height_padding = max_dimension - image_width_height[1]\n",
        "\n",
        "print(\"Width padding: {}, Height padding: {}\".format(width_padding, height_padding))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7Cl6fRyDuDI"
      },
      "source": [
        "We don't want all of the padding to be on one side of the image, though. We need to split the amount of padding in half and then add each half of the padding to each side of the shorter dimension.\n",
        "\n",
        "There is a problem when the padding is an odd number of pixels. A half of a pixel doesn't make sense, so instead we just need to choose a side of the image to put the extra bit of padding onto. In order to do this, we first do integer division to split the padding in half and then use subtraction to find the size of the other portion of the padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsve7z4TFJyk"
      },
      "outputs": [],
      "source": [
        "left_padding = width_padding // 2\n",
        "right_padding = width_padding - left_padding\n",
        "\n",
        "top_padding = height_padding // 2\n",
        "bottom_padding = height_padding - top_padding\n",
        "\n",
        "print(\"Left padding: {}, Top padding {}, Right padding: {}, Bottom padding {}\".format(\n",
        "  left_padding, \n",
        "  top_padding, \n",
        "  right_padding, \n",
        "  bottom_padding))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucstp6tBFt94"
      },
      "source": [
        "Now that we know how much padding to add to the image, we can do so by asking Pillow to expand the image.\n",
        "\n",
        "We asked for the padding to be white (RGBA all `255`). This made sense in this case because this particular image contains one \"object\" and a solid white background. If your images are not so well-produced, you might need to use a different strategy for coloring the image padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uj3FVyQ7Fx_x"
      },
      "outputs": [],
      "source": [
        "from PIL import ImageOps\n",
        "\n",
        "padding = (\n",
        "  left_padding, \n",
        "  top_padding, \n",
        "  right_padding, \n",
        "  bottom_padding\n",
        ")\n",
        "\n",
        "image = Image.open(\"running-shoe-g589ffd24f_1920.jpg\")\n",
        "padded_image = ImageOps.expand(image, padding, (255,255,255,255))\n",
        "image.close()\n",
        "\n",
        "_ = plt.imshow(padded_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG5AIH79JE2F"
      },
      "source": [
        "We will do one final check to confirm that the image is indeed a square now. You should now have a `1920x1920` image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uP8N77nJCcQ"
      },
      "outputs": [],
      "source": [
        "padded_image.size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9Clq0KWL2dD"
      },
      "source": [
        "## Scale the Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8DaPLm2tki9"
      },
      "source": [
        "`1920x1920` is a pretty big image for a machine learning model to handle. If each pixel were used as input, that would be `3,686,400` values in the input vector for a model. It is common for each pixel to have three or four channels for a color image: red, green, blue, alpha. If there are four channels, the actual number of inputs is actually `14,745,600` for this image.\n",
        "\n",
        "A common strategy to reduce the size of the inputs is to scale it down. Let's use Pillow to do that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfhuSpMqfngD"
      },
      "outputs": [],
      "source": [
        "desired_size = (200, 200)\n",
        "\n",
        "resized_image = padded_image.resize(desired_size, Image.ANTIALIAS)\n",
        "_ = plt.imshow(resized_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODIrlPDiJrDP"
      },
      "source": [
        "We can see the exact size of the resized image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFcv3PYzJwjl"
      },
      "outputs": [],
      "source": [
        "resized_image.size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLCSnMlwJy3j"
      },
      "source": [
        "Padding before resizing ensures that we don't distort the shape of the contents of our image, but it did require that we apply an artificial background.\n",
        "\n",
        "We could have also just scaled the image into a `200x200` square and distorted the image.\n",
        "\n",
        "Which is better really depends on what type of image you have coming into your system and the problem you are trying to solve."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdqWCg3eLldl"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs-QlHuc6IbK"
      },
      "source": [
        "## Exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axURTCgJwOjY"
      },
      "source": [
        "Your turn!  Find another sneaker image and make it square and a size of 100 by 100 pixels.  Use your favorite image search website if you don't have a sneaker image handy, e.g.: [Pixabay](https://pixabay.com), [Google Image Search](https://images.google.com), etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJiERBW68otc"
      },
      "source": [
        "### **Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mM2z0RJQfWev"
      },
      "outputs": [],
      "source": [
        "# Upload the file you just downloaded from your computer to the Colab runtime\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlafXcm_wMNc"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###\n",
        "\n",
        "# Open the image file and plot the image\n",
        "image_file = \"shoes-ge42e12e66_1920.jpg\"\n",
        "\n",
        "with Image.open(image_file) as sneaker:\n",
        "  plt.imshow(sneaker)\n",
        "  plt.show()\n",
        "# Print the dimension of the image\n",
        "image_width_height = None\n",
        "\n",
        "with Image.open(image_file) as sneaker:\n",
        "  image_width_height = sneaker.size\n",
        "\n",
        "print(image_width_height)\n",
        "# Find the longer dimension  \n",
        "max_dimension = max(image_width_height)\n",
        "\n",
        "print(max_dimension)\n",
        "\n",
        "# Compute the delta width and height\n",
        "\n",
        "# Compute the padding amounts\n",
        "width_padding = max_dimension - image_width_height[0]\n",
        "height_padding = max_dimension - image_width_height[1]\n",
        "\n",
        "print(\"Width padding: {}, Height padding: {}\".format(width_padding, height_padding))\n",
        "# Pad and plot the image\n",
        "padding = (\n",
        "  left_padding, \n",
        "  top_padding, \n",
        "  right_padding, \n",
        "  bottom_padding\n",
        ")\n",
        "\n",
        "image = Image.open(\"shoes-ge42e12e66_1920.jpg\")\n",
        "padded_image = ImageOps.expand(image, padding, (255,255,255,255))\n",
        "image.close()\n",
        "\n",
        "_ = plt.imshow(padded_image)\n",
        "# Resize and plot the image\n",
        "desired_size = (200, 200)\n",
        "\n",
        "resized_image = padded_image.resize(desired_size, Image.ANTIALIAS)\n",
        "_ = plt.imshow(resized_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF3UCE1VZJlJ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SK6FT1nwFkP"
      },
      "source": [
        "## Exercise 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7EgQSQCwjrK"
      },
      "source": [
        "Pick one of the images above, and do the following:\n",
        "\n",
        "1.   Flip the image horizontally (left to right).\n",
        "2.   Then, save the flipped image back to overwrite the original image file.\n",
        "\n",
        "Resource: [PIL Reference Guide](https://pillow.readthedocs.io/en/3.0.x/reference/ImageOps.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViMkTsVX8zV9"
      },
      "source": [
        "### **Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBTnDLI8ZBry"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###\n",
        "from PIL import Image\n",
        "import PIL\n",
        "# Flip the image horizontally (left to right)\n",
        "from PIL import Image\n",
        "image1 = Image.open(\"shoes-ge42e12e66_1920.jpg\")\n",
        "out = image1.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Npp9LFBI093L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tY0967odCyZs"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###\n",
        "\n",
        "# Save newly generated image to the folder\n",
        "\n",
        "out.save('shoes-ge42e12e66_1920.jpg')\n",
        "out\n",
        "with Image.open(image_file) as sneakers:\n",
        "  plt.imshow(out)\n",
        "  x = plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixGu-OcaZMsj"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "copyright",
        "exercise-1-key-1",
        "exercise-2-key-1"
      ],
      "name": "Manipulating an Image in Python",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}